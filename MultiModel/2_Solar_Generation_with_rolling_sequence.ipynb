{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Solar Generation with rolling sequence",
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7I35Gzz78o1",
        "colab_type": "text"
      },
      "source": [
        "# Modelling Solar generation across Multiple Sites\n",
        "\n",
        "This example shows how `timeserio` helps building deep learning models for time series forecasting. Especially,\n",
        "we deal with the case of many related timeseries.\n",
        "\n",
        "We demonstrate some core functionality and concepts, without striving for model accuracy or seeking out additional features like historic weather forecasts.\n",
        "\n",
        "We will be using the dataset on solar (photo-voltaic, PV) generation potential across Europe, as collected by [SETIS](https://setis.ec.europa.eu/EMHIRES-datasets). The dataset presents solar generation, normalized to the solar capacity installed as of 2015."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bV5HEW69o3vH",
        "colab_type": "code",
        "outputId": "07af3434-b124-4735-d98b-c87f7928f5d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# Restart runtime using 'Runtime' -> 'Restart runtime...'\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR8RNvXO78pj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKCWVUdYlcy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import os.path\n",
        "from os import path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPumjlwOBZmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "def upload_1_file():\n",
        "  uploaded = files.upload()\n",
        "\n",
        "  for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "        name=fn, length=len(uploaded[fn])))\n",
        "    return fn\n",
        "\n",
        "  return \"\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbVwi1u1dpRA",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "def download_1_file(http_path):\n",
        "  import requests\n",
        "  import shutil\n",
        "  response = requests.get(http_path, stream=True)\n",
        "\n",
        "  import tempfile\n",
        "  fname = tempfile.mkstemp()[1]\n",
        "  \n",
        "  #print(fname)\n",
        "  with open(fname, 'wb') as fin:\n",
        "      shutil.copyfileobj(response.raw, fin)\n",
        "\n",
        "  return fname # Works!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH51WPU6jjb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_or_upload_1_file(http_or_file_path):\n",
        "  if (path.exists(http_or_file_path) and (path.isfile(http_or_file_path))):\n",
        "    return http_or_file_path\n",
        "\n",
        "  if (http_or_file_path==\"\"):\n",
        "    encoder_input_file=upload_1_file()\n",
        "    return encoder_input_file\n",
        "  else:\n",
        "    print(http_or_file_path)\n",
        "    return download_1_file(http_or_file_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFrPxsA578pi",
        "colab_type": "text"
      },
      "source": [
        "## Load the data from parquet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b66yLlDxjgDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "selected_path=\"https://MrYingLee.Github.io/MultiModel/selected.parquet\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5KrqfHOkAq4",
        "colab_type": "code",
        "outputId": "2e221c93-5d2e-42fe-a638-aafd29bc92d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "data_file=download_or_upload_1_file(selected_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://MrYingLee.Github.io/MultiModel/selected.parquet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkStn0qBBKdL",
        "colab_type": "code",
        "outputId": "189856d7-1fcb-4fc8-f30f-1217657b54ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "%%time\n",
        "df = pd.read_parquet(data_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 81.8 ms, sys: 51.7 ms, total: 133 ms\n",
            "Wall time: 61.2 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4O34kIqTp4D9",
        "colab_type": "code",
        "outputId": "cf3531d4-c93e-4841-c605-7f80b3dcd6db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time_step</th>\n",
              "      <th>Date</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "      <th>country</th>\n",
              "      <th>generation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1051872</th>\n",
              "      <td>1</td>\n",
              "      <td>1986-01-01 00:00:00</td>\n",
              "      <td>1986</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>UK</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1051873</th>\n",
              "      <td>2</td>\n",
              "      <td>1986-01-01 01:00:00</td>\n",
              "      <td>1986</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>UK</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1051874</th>\n",
              "      <td>3</td>\n",
              "      <td>1986-01-01 02:00:00</td>\n",
              "      <td>1986</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>UK</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1051875</th>\n",
              "      <td>4</td>\n",
              "      <td>1986-01-01 03:00:00</td>\n",
              "      <td>1986</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>UK</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1051876</th>\n",
              "      <td>5</td>\n",
              "      <td>1986-01-01 04:00:00</td>\n",
              "      <td>1986</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>UK</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1051877</th>\n",
              "      <td>6</td>\n",
              "      <td>1986-01-01 05:00:00</td>\n",
              "      <td>1986</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>UK</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1051878</th>\n",
              "      <td>7</td>\n",
              "      <td>1986-01-01 06:00:00</td>\n",
              "      <td>1986</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>UK</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1051879</th>\n",
              "      <td>8</td>\n",
              "      <td>1986-01-01 07:00:00</td>\n",
              "      <td>1986</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>UK</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1051880</th>\n",
              "      <td>9</td>\n",
              "      <td>1986-01-01 08:00:00</td>\n",
              "      <td>1986</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>UK</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1051881</th>\n",
              "      <td>10</td>\n",
              "      <td>1986-01-01 09:00:00</td>\n",
              "      <td>1986</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>UK</td>\n",
              "      <td>0.047485</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Time_step                Date  Year  ...  Hour  country  generation\n",
              "1051872          1 1986-01-01 00:00:00  1986  ...     0       UK    0.000000\n",
              "1051873          2 1986-01-01 01:00:00  1986  ...     1       UK    0.000000\n",
              "1051874          3 1986-01-01 02:00:00  1986  ...     2       UK    0.000000\n",
              "1051875          4 1986-01-01 03:00:00  1986  ...     3       UK    0.000000\n",
              "1051876          5 1986-01-01 04:00:00  1986  ...     4       UK    0.000000\n",
              "1051877          6 1986-01-01 05:00:00  1986  ...     5       UK    0.000000\n",
              "1051878          7 1986-01-01 06:00:00  1986  ...     6       UK    0.000000\n",
              "1051879          8 1986-01-01 07:00:00  1986  ...     7       UK    0.000000\n",
              "1051880          9 1986-01-01 08:00:00  1986  ...     8       UK    0.000000\n",
              "1051881         10 1986-01-01 09:00:00  1986  ...     9       UK    0.047485\n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RxnMQ-W78qM",
        "colab_type": "text"
      },
      "source": [
        "## Split into train-test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp8yaG6_78qN",
        "colab_type": "code",
        "outputId": "c9d5e562-4486-417d-9014-16d260d15695",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "df_dev = df.iloc[:100]\n",
        "df_train, df_test = df[df['Year'] < 2015], df[df['Year'] >= 2015]\n",
        "len(df_train), len(df_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(508416, 17520)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehwOPzGDipPI",
        "colab_type": "code",
        "outputId": "610e53cf-c21e-45e6-af8c-6920586d2414",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "df.groupby(\"Year\").count().reset_index()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Time_step</th>\n",
              "      <th>Date</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "      <th>country</th>\n",
              "      <th>generation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1986</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1987</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1988</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1989</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1990</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1991</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1992</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1993</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1994</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1995</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1996</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1997</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1998</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1999</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2000</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2001</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2002</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2003</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2004</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2005</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2006</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2007</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2008</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2009</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2010</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2011</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2012</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "      <td>17568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2013</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2014</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2015</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "      <td>17520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Year  Time_step   Date  Month    Day   Hour  country  generation\n",
              "0   1986      17520  17520  17520  17520  17520    17520       17520\n",
              "1   1987      17520  17520  17520  17520  17520    17520       17520\n",
              "2   1988      17568  17568  17568  17568  17568    17568       17568\n",
              "3   1989      17520  17520  17520  17520  17520    17520       17520\n",
              "4   1990      17520  17520  17520  17520  17520    17520       17520\n",
              "5   1991      17520  17520  17520  17520  17520    17520       17520\n",
              "6   1992      17568  17568  17568  17568  17568    17568       17568\n",
              "7   1993      17520  17520  17520  17520  17520    17520       17520\n",
              "8   1994      17520  17520  17520  17520  17520    17520       17520\n",
              "9   1995      17520  17520  17520  17520  17520    17520       17520\n",
              "10  1996      17568  17568  17568  17568  17568    17568       17568\n",
              "11  1997      17520  17520  17520  17520  17520    17520       17520\n",
              "12  1998      17520  17520  17520  17520  17520    17520       17520\n",
              "13  1999      17520  17520  17520  17520  17520    17520       17520\n",
              "14  2000      17568  17568  17568  17568  17568    17568       17568\n",
              "15  2001      17520  17520  17520  17520  17520    17520       17520\n",
              "16  2002      17520  17520  17520  17520  17520    17520       17520\n",
              "17  2003      17520  17520  17520  17520  17520    17520       17520\n",
              "18  2004      17568  17568  17568  17568  17568    17568       17568\n",
              "19  2005      17520  17520  17520  17520  17520    17520       17520\n",
              "20  2006      17520  17520  17520  17520  17520    17520       17520\n",
              "21  2007      17520  17520  17520  17520  17520    17520       17520\n",
              "22  2008      17568  17568  17568  17568  17568    17568       17568\n",
              "23  2009      17520  17520  17520  17520  17520    17520       17520\n",
              "24  2010      17520  17520  17520  17520  17520    17520       17520\n",
              "25  2011      17520  17520  17520  17520  17520    17520       17520\n",
              "26  2012      17568  17568  17568  17568  17568    17568       17568\n",
              "27  2013      17520  17520  17520  17520  17520    17520       17520\n",
              "28  2014      17520  17520  17520  17520  17520    17520       17520\n",
              "29  2015      17520  17520  17520  17520  17520    17520       17520"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpJHQuHjwUiW",
        "colab_type": "code",
        "outputId": "60e36899-b5fc-41c5-d9a8-c70197cd2dbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "%%time\n",
        "df_test.to_parquet(\"/content/test.parquet\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 12.9 ms, sys: 3.24 ms, total: 16.2 ms\n",
            "Wall time: 19 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzQcIUAlCRGW",
        "colab_type": "code",
        "outputId": "1b70a58d-9ebd-4337-9f1f-d597807906aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "!ls /content -l"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 312\n",
            "drwxr-xr-x 1 root root   4096 Mar 18 16:23 sample_data\n",
            "-rw-r--r-- 1 root root 313274 Mar 26 02:20 test.parquet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bF9otCaAwUij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import files\n",
        "#files.download(\"/content/test.parquet\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx7XECPPBKdb",
        "colab_type": "text"
      },
      "source": [
        "## Auto-regressive model\n",
        "\n",
        "In an auto-regressive model, we treat past values of the timeseries as input features to the forecasting model.\n",
        "While the functional form of the model is important, deep learning frameworks give us an easy way to try different approaches including CNNs, RNNs, etc.\n",
        "\n",
        "A key part remains however - we must be able to supply abundant training examples, each consisting of a window of consecutive values, the target, and (optinally) the time between the end of the window and the target (the \"forecast horizon\"). A long timeseries can be used to generate many examples simply by sampling the windows randomly from the original timeseries - in fact, for a realistic timeseries, pre-generating training examples in memory is prohibitively expensive. `timeserio` provides a way to generate sequence training examples on-demand from data held in memory, or even from datasets partitioned into multiple files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrDGFTlTDxqE",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "In [Model 1], we have explored the SETIS PV generation dataset and built a powerful and performant model using \n",
        "`timeserio`'s `MultiModel` and datetime feature generation pipelines. In this part, we instead train an auto-regressive model using more advanced batch generator features.\n",
        "\n",
        "Remember the metrics our previous model achieved on the train/test split (without any parameter tuning):\n",
        "\n",
        "|&nbsp;| train | test |\n",
        "|---|---|---|\n",
        "| MSE | 0.0063 | 0.0068 |\n",
        "| MAE | 0.0401 | 0.0424 |\n",
        "\n",
        "In this notebook, we will build a simple model to create short-range predictions (between 1 and 2 hours ahead) based on recent history (say 6h)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJWVwl0VmESV",
        "colab_type": "code",
        "outputId": "4e5d1359-ea87-4490-a93a-212a907b2da8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "!pip install timeserio"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: timeserio in /usr/local/lib/python3.6/dist-packages (0.10.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from timeserio) (0.14.1)\n",
            "Requirement already satisfied: s3fs in /usr/local/lib/python3.6/dist-packages (from timeserio) (0.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from timeserio) (1.18.2)\n",
            "Requirement already satisfied: holidays in /usr/local/lib/python3.6/dist-packages (from timeserio) (0.9.12)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from timeserio) (0.25.3)\n",
            "Requirement already satisfied: scikit-learn==0.20.3 in /usr/local/lib/python3.6/dist-packages (from timeserio) (0.20.3)\n",
            "Requirement already satisfied: boto3>=1.9.91 in /usr/local/lib/python3.6/dist-packages (from s3fs->timeserio) (1.12.26)\n",
            "Requirement already satisfied: botocore>=1.12.91 in /usr/local/lib/python3.6/dist-packages (from s3fs->timeserio) (1.15.26)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from s3fs->timeserio) (0.6.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from holidays->timeserio) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from holidays->timeserio) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->timeserio) (2018.9)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.20.3->timeserio) (1.4.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3>=1.9.91->s3fs->timeserio) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3>=1.9.91->s3fs->timeserio) (0.3.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore>=1.12.91->s3fs->timeserio) (0.15.2)\n",
            "Requirement already satisfied: urllib3<1.26,>=1.20; python_version != \"3.4\" in /usr/local/lib/python3.6/dist-packages (from botocore>=1.12.91->s3fs->timeserio) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MD0G0K_LBKdd",
        "colab_type": "code",
        "outputId": "3c462180-f9c6-40cb-d286-0d9f75d3d8c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from timeserio.batches.chunked.pandas import SequenceForecastBatchGenerator\n",
        "\n",
        "batchgen_train = SequenceForecastBatchGenerator(\n",
        "    df=df_train, batch_size=2**15,\n",
        "    sequence_length=6,\n",
        "    sequence_columns=[\"generation\", \"Time_step\"],\n",
        "    last_step_columns=[\"Time_step\"],\n",
        "    forecast_steps_min=1,\n",
        "    forecast_steps_max=2,\n",
        "    batch_offset=True,\n",
        "    id_column=\"country\",\n",
        "    batch_aggregator=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWqIg9-PBKdh",
        "colab_type": "code",
        "outputId": "ff21fd39-a569-4ed0-f2cd-50cff034da49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "len(batchgen_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hB2j9pKiBKdo",
        "colab_type": "code",
        "outputId": "61e5047a-edf9-4f93-f9b0-a15c4d00b916",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "%%time\n",
        "batch = batchgen_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 57.9 ms, sys: 15 ms, total: 72.9 ms\n",
            "Wall time: 72 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0j4v9p6TBKds",
        "colab_type": "code",
        "outputId": "2f343c69-7efb-46bc-e76f-de92d8bc2f20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "batch.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>country</th>\n",
              "      <th>generation</th>\n",
              "      <th>Time_step</th>\n",
              "      <th colspan=\"6\" halign=\"left\">seq_generation</th>\n",
              "      <th colspan=\"6\" halign=\"left\">seq_Time_step</th>\n",
              "      <th>end_of_Time_step</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>UK</td>\n",
              "      <td>0.164216</td>\n",
              "      <td>12</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.047485</td>\n",
              "      <td>0.109517</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>UK</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>18</td>\n",
              "      <td>0.164216</td>\n",
              "      <td>0.15582</td>\n",
              "      <td>0.12249</td>\n",
              "      <td>0.070279</td>\n",
              "      <td>0.043466</td>\n",
              "      <td>0.016774</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  country generation Time_step seq_generation  ... seq_Time_step         end_of_Time_step\n",
              "                                            0  ...             3   4   5                 \n",
              "0      UK   0.164216        12       0.000000  ...             9  10  11               11\n",
              "1      UK   0.000000        18       0.164216  ...            15  16  17               17\n",
              "\n",
              "[2 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prX0tVORBKdy",
        "colab_type": "code",
        "outputId": "ae5d56bd-8acb-467b-8305-3c55bfc0c8cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "%%time\n",
        "batch = batchgen_train[-1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 61 ms, sys: 4.73 ms, total: 65.7 ms\n",
            "Wall time: 65.1 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCEsNwHeBKd5",
        "colab_type": "code",
        "outputId": "157f38a5-760d-4fee-c47a-1bd9ec2f8aa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "batch.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>country</th>\n",
              "      <th>generation</th>\n",
              "      <th>Time_step</th>\n",
              "      <th colspan=\"6\" halign=\"left\">seq_generation</th>\n",
              "      <th colspan=\"6\" halign=\"left\">seq_Time_step</th>\n",
              "      <th>end_of_Time_step</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ES</td>\n",
              "      <td>0.591977</td>\n",
              "      <td>196620</td>\n",
              "      <td>0.027444</td>\n",
              "      <td>0.080617</td>\n",
              "      <td>0.211192</td>\n",
              "      <td>0.318396</td>\n",
              "      <td>0.493836</td>\n",
              "      <td>0.515103</td>\n",
              "      <td>196614</td>\n",
              "      <td>196615</td>\n",
              "      <td>196616</td>\n",
              "      <td>196617</td>\n",
              "      <td>196618</td>\n",
              "      <td>196619</td>\n",
              "      <td>196619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ES</td>\n",
              "      <td>0.088870</td>\n",
              "      <td>196627</td>\n",
              "      <td>0.591977</td>\n",
              "      <td>0.621796</td>\n",
              "      <td>0.608276</td>\n",
              "      <td>0.565962</td>\n",
              "      <td>0.474634</td>\n",
              "      <td>0.345412</td>\n",
              "      <td>196620</td>\n",
              "      <td>196621</td>\n",
              "      <td>196622</td>\n",
              "      <td>196623</td>\n",
              "      <td>196624</td>\n",
              "      <td>196625</td>\n",
              "      <td>196625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  country generation Time_step  ... seq_Time_step         end_of_Time_step\n",
              "                                ...             4       5                 \n",
              "0      ES   0.591977    196620  ...        196618  196619           196619\n",
              "1      ES   0.088870    196627  ...        196624  196625           196625\n",
              "\n",
              "[2 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jslSgu-OBKd9",
        "colab_type": "text"
      },
      "source": [
        "### Sequence and Forecast horizon features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDYZ_oNEBKd-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from timeserio.pipeline import Pipeline\n",
        "from timeserio.preprocessing import PandasColumnSelector, PandasValueSelector\n",
        "\n",
        "class ColumnDifferenceValues:\n",
        "    \"\"\"Compute difference feature of two columns\"\"\"\n",
        "    def __init__(self, *, col_plus, col_minus):\n",
        "        self.col_plus = col_plus\n",
        "        self.col_minus = col_minus\n",
        "    \n",
        "    def fit(self, *args, **kwargs):\n",
        "        return self\n",
        "    \n",
        "    def fit_transform(self, df, *args, **kwargs):\n",
        "        return self.transform(df, *args, **kwargs)\n",
        "\n",
        "    def transform(self, df, *args, **kwargs):\n",
        "        return (df[self.col_plus] - df[self.col_minus]).values.reshape(-1, 1)\n",
        "\n",
        "    \n",
        "seq_pipeline = PandasValueSelector(\"back_generation\")\n",
        "fc_horizon_pipeline = ColumnDifferenceValues(col_plus=\"Time_step\", col_minus=\"end_of_Time_step\")\n",
        "target_pipeline = PandasValueSelector(\"fore_generation\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxA61HJkBKeB",
        "colab_type": "text"
      },
      "source": [
        "### Define the Neural Network Architecture\n",
        "\n",
        "We define a regression network with two inputs: sequence of previous readings, and the forecast horizon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nvu1j_9LBKeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from timeserio.keras.multinetwork import MultiNetworkBase\n",
        "\n",
        "from keras.layers import Input, Dense, Flatten, Concatenate, Reshape, Permute, Conv1D, BatchNormalization, MaxPool1D, Activation\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "class ARForecastingNetwork(MultiNetworkBase):\n",
        "    def _model(\n",
        "        self,\n",
        "        *,\n",
        "        seq_length=6,  # number of real-valued features\n",
        "        filters=(1, ),\n",
        "        kernel_sizes=(1, ),\n",
        "        strides=(1, ),\n",
        "        pools=(1, ),\n",
        "        hidden_units=(8, 8),\n",
        "        lr=0.01\n",
        "    ):\n",
        "        horizon_input = Input(shape=(1,), name='horizon')\n",
        "        seq_input = Input(shape=(seq_length,), name='sequence')\n",
        "        encoding = Reshape(\n",
        "            target_shape=(-1, 1)\n",
        "        )(seq_input)\n",
        "                \n",
        "        for idx, (_filters, _kernel_size, _strides, _pool) in enumerate(zip(filters, kernel_sizes, strides, pools)):\n",
        "            encoding = Conv1D(filters=_filters, kernel_size=_kernel_size, strides=_strides, padding=\"same\", name=f\"conv_{idx}\")(encoding)\n",
        "            encoding = BatchNormalization()(encoding)\n",
        "            encoding = Activation(activation='relu')(encoding)\n",
        "            encoding = MaxPool1D(pool_size=_pool)(encoding)\n",
        "        encoding = Flatten()(encoding)\n",
        "\n",
        "        output = Concatenate(name='concatenate')([encoding, horizon_input])\n",
        "        for idx, _hidden_units in enumerate(hidden_units):\n",
        "            output = Dense(_hidden_units, activation='relu', name=f'dense_{idx}')(output)\n",
        "        output = Dense(2, name='fore_generation', activation='relu')(output) # 1=>2\n",
        "        \n",
        "        encoding_model = Model(seq_input, encoding)\n",
        "        forecasting_model = Model([seq_input, horizon_input], output)\n",
        "        \n",
        "        optimizer = Adam(lr=lr)\n",
        "        forecasting_model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
        "        \n",
        "        return {'encoder': encoding_model, 'forecast': forecasting_model}\n",
        "\n",
        "    \n",
        "multinetwork = ARForecastingNetwork(seq_length=6, lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnOlhZ0xBKeG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "def vis_model(model, show_shapes=False, show_layer_names=True, rankdir='TB'):\n",
        "    \"\"\"Visualize model in a notebook.\"\"\"\n",
        "    return SVG(\n",
        "        model_to_dot(\n",
        "            model, show_shapes=show_shapes, show_layer_names=show_layer_names, rankdir=rankdir\n",
        "        ).create(prog='dot', format='svg')\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnaGCVl8BKeM",
        "colab_type": "code",
        "outputId": "7755d222-6a28-48c4-80ec-b33e185f7598",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "vis_model(multinetwork.model[\"forecast\"], show_shapes=True, rankdir=\"LR\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"221pt\" viewBox=\"0.00 0.00 2323.00 166.00\" width=\"3097pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 162)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-162 2319,-162 2319,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140408460501680 -->\n<g class=\"node\" id=\"node1\">\n<title>140408460501680</title>\n<polygon fill=\"none\" points=\"0,-88.5 0,-157.5 144,-157.5 144,-88.5 0,-88.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"72\" y=\"-142.3\">sequence: InputLayer</text>\n<polyline fill=\"none\" points=\"0,-134.5 144,-134.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"34\" y=\"-119.3\">input:</text>\n<polyline fill=\"none\" points=\"68,-111.5 68,-134.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"106\" y=\"-119.3\">output:</text>\n<polyline fill=\"none\" points=\"0,-111.5 144,-111.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"36\" y=\"-96.3\">(None, 6)</text>\n<polyline fill=\"none\" points=\"72,-88.5 72,-111.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"108\" y=\"-96.3\">(None, 6)</text>\n</g>\n<!-- 140408460501904 -->\n<g class=\"node\" id=\"node2\">\n<title>140408460501904</title>\n<polygon fill=\"none\" points=\"180,-88.5 180,-157.5 339,-157.5 339,-88.5 180,-88.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"259.5\" y=\"-142.3\">reshape_1: Reshape</text>\n<polyline fill=\"none\" points=\"180,-134.5 339,-134.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"217.5\" y=\"-119.3\">input:</text>\n<polyline fill=\"none\" points=\"255,-111.5 255,-134.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"297\" y=\"-119.3\">output:</text>\n<polyline fill=\"none\" points=\"180,-111.5 339,-111.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"216\" y=\"-96.3\">(None, 6)</text>\n<polyline fill=\"none\" points=\"252,-88.5 252,-111.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"295.5\" y=\"-96.3\">(None, 6, 1)</text>\n</g>\n<!-- 140408460501680&#45;&gt;140408460501904 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140408460501680-&gt;140408460501904</title>\n<path d=\"M144.2242,-123C152.603,-123 161.2242,-123 169.8002,-123\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"169.8297,-126.5001 179.8297,-123 169.8296,-119.5001 169.8297,-126.5001\" stroke=\"#000000\"/>\n</g>\n<!-- 140408719839128 -->\n<g class=\"node\" id=\"node3\">\n<title>140408719839128</title>\n<polygon fill=\"none\" points=\"375,-88.5 375,-157.5 549,-157.5 549,-88.5 375,-88.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"462\" y=\"-142.3\">conv_0: Conv1D</text>\n<polyline fill=\"none\" points=\"375,-134.5 549,-134.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"416.5\" y=\"-119.3\">input:</text>\n<polyline fill=\"none\" points=\"458,-111.5 458,-134.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"503.5\" y=\"-119.3\">output:</text>\n<polyline fill=\"none\" points=\"375,-111.5 549,-111.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"418.5\" y=\"-96.3\">(None, 6, 1)</text>\n<polyline fill=\"none\" points=\"462,-88.5 462,-111.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"505.5\" y=\"-96.3\">(None, 6, 1)</text>\n</g>\n<!-- 140408460501904&#45;&gt;140408719839128 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140408460501904-&gt;140408719839128</title>\n<path d=\"M339.2427,-123C347.675,-123 356.3159,-123 364.9167,-123\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"364.9799,-126.5001 374.9799,-123 364.9798,-119.5001 364.9799,-126.5001\" stroke=\"#000000\"/>\n</g>\n<!-- 140408460356240 -->\n<g class=\"node\" id=\"node4\">\n<title>140408460356240</title>\n<polygon fill=\"none\" points=\"585,-88.5 585,-157.5 856,-157.5 856,-88.5 585,-88.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"720.5\" y=\"-142.3\">batch_normalization_1: BatchNormalization</text>\n<polyline fill=\"none\" points=\"585,-134.5 856,-134.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"650.5\" y=\"-119.3\">input:</text>\n<polyline fill=\"none\" points=\"716,-111.5 716,-134.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"786\" y=\"-119.3\">output:</text>\n<polyline fill=\"none\" points=\"585,-111.5 856,-111.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"652.5\" y=\"-96.3\">(None, 6, 1)</text>\n<polyline fill=\"none\" points=\"720,-88.5 720,-111.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"788\" y=\"-96.3\">(None, 6, 1)</text>\n</g>\n<!-- 140408719839128&#45;&gt;140408460356240 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140408719839128-&gt;140408460356240</title>\n<path d=\"M549.1559,-123C557.4785,-123 566.0625,-123 574.7476,-123\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"574.9799,-126.5001 584.9799,-123 574.9798,-119.5001 574.9799,-126.5001\" stroke=\"#000000\"/>\n</g>\n<!-- 140408460356128 -->\n<g class=\"node\" id=\"node5\">\n<title>140408460356128</title>\n<polygon fill=\"none\" points=\"892,-88.5 892,-157.5 1066,-157.5 1066,-88.5 892,-88.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"979\" y=\"-142.3\">activation_1: Activation</text>\n<polyline fill=\"none\" points=\"892,-134.5 1066,-134.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"933.5\" y=\"-119.3\">input:</text>\n<polyline fill=\"none\" points=\"975,-111.5 975,-134.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1020.5\" y=\"-119.3\">output:</text>\n<polyline fill=\"none\" points=\"892,-111.5 1066,-111.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"935.5\" y=\"-96.3\">(None, 6, 1)</text>\n<polyline fill=\"none\" points=\"979,-88.5 979,-111.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1022.5\" y=\"-96.3\">(None, 6, 1)</text>\n</g>\n<!-- 140408460356240&#45;&gt;140408460356128 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140408460356240-&gt;140408460356128</title>\n<path d=\"M856.1849,-123C864.7642,-123 873.3057,-123 881.6575,-123\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"881.7407,-126.5001 891.7406,-123 881.7406,-119.5001 881.7407,-126.5001\" stroke=\"#000000\"/>\n</g>\n<!-- 140408460089944 -->\n<g class=\"node\" id=\"node6\">\n<title>140408460089944</title>\n<polygon fill=\"none\" points=\"1102,-88.5 1102,-157.5 1323,-157.5 1323,-88.5 1102,-88.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1212.5\" y=\"-142.3\">max_pooling1d_1: MaxPooling1D</text>\n<polyline fill=\"none\" points=\"1102,-134.5 1323,-134.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1155\" y=\"-119.3\">input:</text>\n<polyline fill=\"none\" points=\"1208,-111.5 1208,-134.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1265.5\" y=\"-119.3\">output:</text>\n<polyline fill=\"none\" points=\"1102,-111.5 1323,-111.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1157\" y=\"-96.3\">(None, 6, 1)</text>\n<polyline fill=\"none\" points=\"1212,-88.5 1212,-111.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1267.5\" y=\"-96.3\">(None, 6, 1)</text>\n</g>\n<!-- 140408460356128&#45;&gt;140408460089944 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140408460356128-&gt;140408460089944</title>\n<path d=\"M1066.2788,-123C1074.5651,-123 1083.0632,-123 1091.591,-123\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1091.6046,-126.5001 1101.6046,-123 1091.6046,-119.5001 1091.6046,-126.5001\" stroke=\"#000000\"/>\n</g>\n<!-- 140408460501960 -->\n<g class=\"node\" id=\"node7\">\n<title>140408460501960</title>\n<polygon fill=\"none\" points=\"1359,-88.5 1359,-157.5 1518,-157.5 1518,-88.5 1359,-88.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1438.5\" y=\"-142.3\">flatten_1: Flatten</text>\n<polyline fill=\"none\" points=\"1359,-134.5 1518,-134.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1396.5\" y=\"-119.3\">input:</text>\n<polyline fill=\"none\" points=\"1434,-111.5 1434,-134.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1476\" y=\"-119.3\">output:</text>\n<polyline fill=\"none\" points=\"1359,-111.5 1518,-111.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1402.5\" y=\"-96.3\">(None, 6, 1)</text>\n<polyline fill=\"none\" points=\"1446,-88.5 1446,-111.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1482\" y=\"-96.3\">(None, 6)</text>\n</g>\n<!-- 140408460089944&#45;&gt;140408460501960 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140408460089944-&gt;140408460501960</title>\n<path d=\"M1323.1828,-123C1331.7699,-123 1340.3749,-123 1348.7993,-123\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1348.9724,-126.5001 1358.9723,-123 1348.9723,-119.5001 1348.9724,-126.5001\" stroke=\"#000000\"/>\n</g>\n<!-- 140408460321456 -->\n<g class=\"node\" id=\"node9\">\n<title>140408460321456</title>\n<polygon fill=\"none\" points=\"1554,-44.5 1554,-113.5 1770,-113.5 1770,-44.5 1554,-44.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1662\" y=\"-98.3\">concatenate: Concatenate</text>\n<polyline fill=\"none\" points=\"1554,-90.5 1770,-90.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1606\" y=\"-75.3\">input:</text>\n<polyline fill=\"none\" points=\"1658,-67.5 1658,-90.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1714\" y=\"-75.3\">output:</text>\n<polyline fill=\"none\" points=\"1554,-67.5 1770,-67.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1626\" y=\"-52.3\">[(None, 6), (None, 1)]</text>\n<polyline fill=\"none\" points=\"1698,-44.5 1698,-67.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1734\" y=\"-52.3\">(None, 7)</text>\n</g>\n<!-- 140408460501960&#45;&gt;140408460321456 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140408460501960-&gt;140408460321456</title>\n<path d=\"M1518.2421,-107.3013C1526.6218,-105.6516 1535.2638,-103.9503 1543.9567,-102.2389\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1544.6462,-105.6705 1553.7817,-100.3047 1543.294,-98.8023 1544.6462,-105.6705\" stroke=\"#000000\"/>\n</g>\n<!-- 140408460501064 -->\n<g class=\"node\" id=\"node8\">\n<title>140408460501064</title>\n<polygon fill=\"none\" points=\"1366.5,-.5 1366.5,-69.5 1510.5,-69.5 1510.5,-.5 1366.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1438.5\" y=\"-54.3\">horizon: InputLayer</text>\n<polyline fill=\"none\" points=\"1366.5,-46.5 1510.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1400.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"1434.5,-23.5 1434.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1472.5\" y=\"-31.3\">output:</text>\n<polyline fill=\"none\" points=\"1366.5,-23.5 1510.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1402.5\" y=\"-8.3\">(None, 1)</text>\n<polyline fill=\"none\" points=\"1438.5,-.5 1438.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1474.5\" y=\"-8.3\">(None, 1)</text>\n</g>\n<!-- 140408460501064&#45;&gt;140408460321456 -->\n<g class=\"edge\" id=\"edge8\">\n<title>140408460501064-&gt;140408460321456</title>\n<path d=\"M1510.7554,-49.2248C1521.4087,-51.3221 1532.6115,-53.5276 1543.9011,-55.7501\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1543.3451,-59.2078 1553.8329,-57.7054 1544.6973,-52.3396 1543.3451,-59.2078\" stroke=\"#000000\"/>\n</g>\n<!-- 140408459972336 -->\n<g class=\"node\" id=\"node10\">\n<title>140408459972336</title>\n<polygon fill=\"none\" points=\"1806,-44.5 1806,-113.5 1950,-113.5 1950,-44.5 1806,-44.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1878\" y=\"-98.3\">dense_0: Dense</text>\n<polyline fill=\"none\" points=\"1806,-90.5 1950,-90.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1840\" y=\"-75.3\">input:</text>\n<polyline fill=\"none\" points=\"1874,-67.5 1874,-90.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1912\" y=\"-75.3\">output:</text>\n<polyline fill=\"none\" points=\"1806,-67.5 1950,-67.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1842\" y=\"-52.3\">(None, 7)</text>\n<polyline fill=\"none\" points=\"1878,-44.5 1878,-67.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1914\" y=\"-52.3\">(None, 8)</text>\n</g>\n<!-- 140408460321456&#45;&gt;140408459972336 -->\n<g class=\"edge\" id=\"edge9\">\n<title>140408460321456-&gt;140408459972336</title>\n<path d=\"M1770.3164,-79C1778.8476,-79 1787.3761,-79 1795.6891,-79\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1795.708,-82.5001 1805.7079,-79 1795.7079,-75.5001 1795.708,-82.5001\" stroke=\"#000000\"/>\n</g>\n<!-- 140408459478072 -->\n<g class=\"node\" id=\"node11\">\n<title>140408459478072</title>\n<polygon fill=\"none\" points=\"1986,-44.5 1986,-113.5 2130,-113.5 2130,-44.5 1986,-44.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2058\" y=\"-98.3\">dense_1: Dense</text>\n<polyline fill=\"none\" points=\"1986,-90.5 2130,-90.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2020\" y=\"-75.3\">input:</text>\n<polyline fill=\"none\" points=\"2054,-67.5 2054,-90.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2092\" y=\"-75.3\">output:</text>\n<polyline fill=\"none\" points=\"1986,-67.5 2130,-67.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2022\" y=\"-52.3\">(None, 8)</text>\n<polyline fill=\"none\" points=\"2058,-44.5 2058,-67.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2094\" y=\"-52.3\">(None, 8)</text>\n</g>\n<!-- 140408459972336&#45;&gt;140408459478072 -->\n<g class=\"edge\" id=\"edge10\">\n<title>140408459972336-&gt;140408459478072</title>\n<path d=\"M1950.1757,-79C1958.5199,-79 1967.0771,-79 1975.5445,-79\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1975.8081,-82.5001 1985.8081,-79 1975.808,-75.5001 1975.8081,-82.5001\" stroke=\"#000000\"/>\n</g>\n<!-- 140408460322576 -->\n<g class=\"node\" id=\"node12\">\n<title>140408460322576</title>\n<polygon fill=\"none\" points=\"2166,-44.5 2166,-113.5 2315,-113.5 2315,-44.5 2166,-44.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2240.5\" y=\"-98.3\">fore_generation: Dense</text>\n<polyline fill=\"none\" points=\"2166,-90.5 2315,-90.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2201\" y=\"-75.3\">input:</text>\n<polyline fill=\"none\" points=\"2236,-67.5 2236,-90.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2275.5\" y=\"-75.3\">output:</text>\n<polyline fill=\"none\" points=\"2166,-67.5 2315,-67.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2203\" y=\"-52.3\">(None, 8)</text>\n<polyline fill=\"none\" points=\"2240,-44.5 2240,-67.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2277.5\" y=\"-52.3\">(None, 2)</text>\n</g>\n<!-- 140408459478072&#45;&gt;140408460322576 -->\n<g class=\"edge\" id=\"edge11\">\n<title>140408459478072-&gt;140408460322576</title>\n<path d=\"M2130.1288,-79C2138.5789,-79 2147.2581,-79 2155.8585,-79\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"2155.9001,-82.5001 2165.9001,-79 2155.9,-75.5001 2155.9001,-82.5001\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAyAcdZZBKeQ",
        "colab_type": "text"
      },
      "source": [
        "### Connect feature pipelines to the neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chARUG6WBKeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from timeserio.pipeline import MultiPipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fZpcQstBKeV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "multipipeline = MultiPipeline({\n",
        "    \"sequence\": seq_pipeline,\n",
        "    \"horizon\": fc_horizon_pipeline,\n",
        "    \"target\": target_pipeline\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oAq1WYuBKea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from timeserio.multimodel import MultiModel\n",
        "\n",
        "manifold = {\n",
        "    # keras_model_name: (input_pipes, output_pipes)\n",
        "    \"encoder\": (\"sequence\", None),\n",
        "    \"forecast\": ([\"sequence\", \"horizon\"], \"target\")\n",
        "}\n",
        "\n",
        "multimodel = MultiModel(\n",
        "    multinetwork=multinetwork,\n",
        "    multipipeline=multipipeline,\n",
        "    manifold=manifold\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMT83C6BBKed",
        "colab_type": "text"
      },
      "source": [
        "### Fit model from the batch generator\n",
        "\n",
        "`multimodel.fit_generator()` will apply pipelines correctly to the training batch generator, and, if `validation_data` is provided in the form of another (pandas) batch generator,\n",
        "evaluate the relevant metrics. In addition, feature extraction for each batch will benefit from the `workers` parallelism."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6cuAZXADihe",
        "colab_type": "code",
        "outputId": "76767281-9b3d-40b0-8bcd-5ed58ce35dc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "!pip install kerashistoryplot"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kerashistoryplot in /usr/local/lib/python3.6/dist-packages (0.0.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVwK7Epz-oMR",
        "colab_type": "text"
      },
      "source": [
        "### Rolling Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nn6s34xY-nD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdf1oiTgGV1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pytest\n",
        "\n",
        "import timeserio.ini as ini\n",
        "from timeserio.data.mock import mock_fit_data, mock_raw_data\n",
        "from timeserio.batches.single.sequence import (\n",
        "    SamplingForecastBatchGenerator, SequenceForecastBatchGenerator, ForecastBatchGeneratorBase, BatchGenerator\n",
        ")\n",
        "from numpy.testing import assert_array_equal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aypt_3kbJggA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import abc\n",
        "import functools\n",
        "from typing import Union\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from  timeserio import ini\n",
        "from timeserio.preprocessing.pandas import array_to_dataframe\n",
        "from timeserio.batches.utils import ceiling_division"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMyaMEkjiJZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RollingSequenceBatchGenerator(BatchGenerator):\n",
        "   \"\"\"Generate batches of sequence forecast examples.\n",
        "   Assume single continuous timeseries.\n",
        "   \"\"\"\n",
        "   def __init__(\n",
        "       self,\n",
        "       *,\n",
        "       df,\n",
        "       batch_size: Union[None, int] = None,\n",
        " \n",
        "       lookback_steps=2, # The steps of look back (history)\n",
        "       lookback_columns=[ini.Columns.datetime, ini.Columns.target],\n",
        "       lookback_prefix='back_',\n",
        "       \n",
        "       forecast_steps=1,  # The steps of forecasting\n",
        "       forecast_columns=[ini.Columns.target],\n",
        "       forecast_prefix='fore_',\n",
        "              \n",
        "       id_column=None,\n",
        "       last_step_columns=[ini.Columns.datetime],\n",
        "       last_step_prefix='end_of_',\n",
        "       dt_column=ini.Columns.datetime,\n",
        "       start_time=None\n",
        "   ):\n",
        "       self.df = df\n",
        "       self.batch_size = batch_size\n",
        "       self.lookback_steps = lookback_steps\n",
        "       self.lookback_columns = lookback_columns\n",
        "       self.lookback_prefix = lookback_prefix\n",
        " \n",
        "       self.forecast_steps = forecast_steps\n",
        "       self.forecast_columns = forecast_columns\n",
        "       self.forecast_prefix = forecast_prefix\n",
        "              \n",
        "       self.last_step_columns = last_step_columns\n",
        "       self.last_step_prefix = last_step_prefix\n",
        " \n",
        "       if lookback_columns:\n",
        "           if not lookback_prefix:\n",
        "               raise ValueError('`lookback_prefix` must be non-empty')\n",
        " \n",
        "       if last_step_columns:\n",
        "           if not (set(last_step_columns) <= set(lookback_columns)):\n",
        "               raise ValueError('`last_step_columns` must be a subset of '\n",
        "                                '`lookback_columns`')\n",
        "       if not forecast_columns:\n",
        "           raise ValueError('`forecast_columns` must be non-empty')\n",
        " \n",
        "       if not (set(forecast_columns) <= set(lookback_columns)):\n",
        "           raise ValueError('`forecast_columns` must be a subset of '\n",
        "                                '`lookback_columns`')\n",
        "       if not last_step_prefix:\n",
        "           raise ValueError('`last_step_prefix` must be non-empty')\n",
        "      \n",
        "       if last_step_prefix == lookback_prefix:\n",
        "            raise ValueError('`last_step_prefix` must be '\n",
        "                            'different from `lookback_prefix`')\n",
        "\n",
        "       self.dt_column = dt_column\n",
        "       self.start_time = start_time\n",
        " \n",
        "   @property\n",
        "   def num_points(self):\n",
        "       \"\"\"Return number of rows in original timeseries.\"\"\"\n",
        "       return len(self.df)\n",
        " \n",
        "   @property  # type: ignore\n",
        "   @functools.lru_cache(None)\n",
        "   def first_index(self):\n",
        "       if self.start_time is None:\n",
        "           return 0\n",
        "       times = self.df[self.dt_column].dt.time.values\n",
        "       first_idx = np.argmax(times == self.start_time)\n",
        "       if not first_idx and times[0] != self.start_time:\n",
        "           raise ValueError(f'Start time {self.start_time} not found in df')\n",
        "       return first_idx\n",
        " \n",
        "   @property\n",
        "   def num_examples(self):\n",
        "       \"\"\"Return number of examples to yield in one epoch.\"\"\"\n",
        "       return max(0,self.num_points-self.lookback_steps - self.forecast_steps -self.first_index+1)\n",
        "      \n",
        "   @property\n",
        "   def _eff_batch_size(self):\n",
        "       return self.batch_size or self.num_examples\n",
        " \n",
        "   def __len__(self):\n",
        "       return ceiling_division(self.num_examples, self._eff_batch_size)\n",
        " \n",
        "   def batch_seq_start_indices(self, batch_idx):\n",
        "       start_indices = np.arange(\n",
        "           self._eff_batch_size * batch_idx,\n",
        "           min(self._eff_batch_size * (batch_idx + 1), self.num_examples)\n",
        "       )\n",
        "       return self.first_index + start_indices\n",
        " \n",
        "   def _get_lookback_values(self, column, start_indices):\n",
        "       values = self.df[column].values\n",
        "       cols = [\n",
        "           values[start_indices + s] for s in range(self.lookback_steps)\n",
        "       ]\n",
        "       seq_values = np.vstack(cols).T\n",
        "       return seq_values\n",
        "      \n",
        "   def _get_forecast_values(self, column, start_indices):\n",
        "       values = self.df[column].values\n",
        "       cols = [\n",
        "           values[start_indices + self.lookback_steps + s ] for s in range(self.forecast_steps)\n",
        "       ]\n",
        "       seq_values = np.vstack(cols).T\n",
        "       return seq_values\n",
        " \n",
        "   def __getitem__(self, batch_idx):\n",
        "       if not len(self):\n",
        "           raise IndexError('Batch index out of range: Empty batch generator')\n",
        "       batch_idx = batch_idx % len(self)\n",
        "       start_indices = self.batch_seq_start_indices(batch_idx)\n",
        "       batch_size = len(start_indices)\n",
        "       end_indices = start_indices + self.lookback_steps\n",
        "       fc_indices = end_indices\n",
        "       cols = []\n",
        "       lookback_columns = self.lookback_columns or []\n",
        "       forecast_columns = self.forecast_columns or []\n",
        "       last_step_columns = self.last_step_columns or []\n",
        " \n",
        "       cols = cols + lookback_columns\n",
        "       batch_df = self.df[cols].iloc[fc_indices].copy()\n",
        "       batch_df.reset_index(drop=True, inplace=True)\n",
        "       for column in lookback_columns:\n",
        "           seq_values = self._get_lookback_values(\n",
        "               column, start_indices\n",
        "           )\n",
        "           seq_col_name = self.lookback_prefix + column\n",
        "           batch_df = array_to_dataframe(\n",
        "               seq_values,\n",
        "               column=seq_col_name,\n",
        "               df=batch_df\n",
        "           )\n",
        "\n",
        "       #if forecast_steps>1: \n",
        "       for column in forecast_columns:\n",
        "           seq_values = self._get_forecast_values(\n",
        "               column, start_indices\n",
        "           )\n",
        "           seq_col_name = self.forecast_prefix + column\n",
        "           batch_df = array_to_dataframe(\n",
        "               seq_values,\n",
        "               column=seq_col_name,\n",
        "               df=batch_df\n",
        "           )\n",
        "\n",
        "       for column in last_step_columns:\n",
        "           seq_col_name = self.lookback_prefix + column\n",
        "           last_step_col_name = self.last_step_prefix + column\n",
        "           batch_df[last_step_col_name] = batch_df[seq_col_name].iloc[:, -1]\n",
        " \n",
        "       return batch_df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oqEcw8vjY87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Generate batches from pandas DataFrame.\"\"\"\n",
        "from typing import Union\n",
        "\n",
        "from timeserio.batches.chunked.base import ChunkedBatchGenerator\n",
        "from timeserio import ini\n",
        "\n",
        "single_sequence= RollingSequenceBatchGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zVbcbD5bi_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RollingForecastBatchGeneratorChunked(ChunkedBatchGenerator):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        df,\n",
        "        batch_size: Union[None, int] = None,\n",
        "\n",
        "        lookback_steps=2, # The steps of look back (history)\n",
        "        lookback_columns=[ini.Columns.datetime, ini.Columns.target],\n",
        "        lookback_prefix='back_',\n",
        "        \n",
        "        forecast_steps=1,  # The steps of forecasting\n",
        "        forecast_columns=[ini.Columns.target],\n",
        "        forecast_prefix='fore_',\n",
        "                \n",
        "        id_column=None,\n",
        "        last_step_columns=[ini.Columns.datetime],\n",
        "        last_step_prefix='end_of_',\n",
        "        dt_column=ini.Columns.datetime,\n",
        "        start_time=None,\n",
        "\n",
        "        batch_aggregator=1\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.df = df\n",
        "        self.batch_size = batch_size\n",
        "        self.lookback_steps = lookback_steps\n",
        "        self.lookback_columns = lookback_columns\n",
        "        self.lookback_prefix = lookback_prefix\n",
        "  \n",
        "        self.forecast_steps = forecast_steps\n",
        "        self.forecast_columns = forecast_columns\n",
        "        self.forecast_prefix = forecast_prefix\n",
        "                \n",
        "        self.last_step_columns = last_step_columns\n",
        "        self.last_step_prefix = last_step_prefix\n",
        "  \n",
        "        if lookback_columns:\n",
        "            if not lookback_prefix:\n",
        "                raise ValueError('`lookback_prefix` must be non-empty')\n",
        "  \n",
        "        if last_step_columns:\n",
        "            if not (set(last_step_columns) <= set(lookback_columns)):\n",
        "                raise ValueError('`last_step_columns` must be a subset of '\n",
        "                                  '`lookback_columns`')\n",
        "        if not forecast_columns:\n",
        "            raise ValueError('`forecast_columns` must be non-empty')\n",
        "  \n",
        "        if not (set(forecast_columns) <= set(lookback_columns)):\n",
        "            raise ValueError('`forecast_columns` must be a subset of '\n",
        "                                  '`lookback_columns`')\n",
        "        if not last_step_prefix:\n",
        "            raise ValueError('`last_step_prefix` must be non-empty')\n",
        "        \n",
        "        if last_step_prefix == lookback_prefix:\n",
        "              raise ValueError('`last_step_prefix` must be '\n",
        "                              'different from `lookback_prefix`')\n",
        "\n",
        "        self.id_column = id_column\n",
        "        self.dt_column = dt_column\n",
        "        self.start_time = start_time\n",
        "       \n",
        "        self.subgens = []  # type: ignore\n",
        "        self.batch_aggregator = batch_aggregator\n",
        "        self.unique_ids = self.df[self.id_column].unique()\n",
        "\n",
        "    @property\n",
        "    def chunks(self):\n",
        "        return self.unique_ids\n",
        "\n",
        "    def make_subgen(self, chunk):\n",
        "        cust_id = chunk\n",
        "        subgen = single_sequence(\n",
        "            df=self.df[self.df[self.id_column] == cust_id],\n",
        "            batch_size=self.batch_size,\n",
        "            id_column=self.id_column,\n",
        "            \n",
        "            last_step_columns=self.last_step_columns,\n",
        "            last_step_prefix=self.last_step_prefix,\n",
        "            \n",
        "            dt_column=self.dt_column,\n",
        "            start_time=self.start_time,\n",
        " \n",
        "            lookback_steps=self.lookback_steps, # The steps of look back (history)\n",
        "            lookback_columns=self.lookback_columns,\n",
        "            lookback_prefix=self.lookback_prefix,\n",
        "            \n",
        "            forecast_steps=self.forecast_steps,  # The steps of forecasting\n",
        "            forecast_columns=self.forecast_columns,\n",
        "            forecast_prefix=self.forecast_prefix\n",
        "        )\n",
        "        return subgen"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUROxEiPCMvG",
        "colab_type": "text"
      },
      "source": [
        "### Rolling Generator declare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99muFhJ0-8ju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rolling_chunked=RollingForecastBatchGeneratorChunked(\n",
        "    df=df_train,id_column=\"country\",lookback_steps=6,forecast_steps=2,lookback_columns=[\"generation\", \"Time_step\"],\n",
        "    forecast_columns=[\"generation\"],\n",
        "     last_step_columns=[\"Time_step\"] ,batch_size=2**15,\n",
        "     )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSsEo93RAc5X",
        "colab_type": "code",
        "outputId": "5bc8be51-dee4-4c5f-d5ad-2d76701c4329",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "rolling_chunked.chunks"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['UK', 'ES'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joeUeh7sAgm9",
        "colab_type": "code",
        "outputId": "91d39c6f-8e64-4db2-b12f-d2838a1f9594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        }
      },
      "source": [
        "sub0=rolling_chunked.make_subgen('UK')\n",
        "sub0[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>generation</th>\n",
              "      <th>Time_step</th>\n",
              "      <th colspan=\"6\" halign=\"left\">back_generation</th>\n",
              "      <th colspan=\"6\" halign=\"left\">back_Time_step</th>\n",
              "      <th colspan=\"2\" halign=\"left\">fore_generation</th>\n",
              "      <th>end_of_Time_step</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.047485</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.047485</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>0.047485</td>\n",
              "      <td>0.109517</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.109517</td>\n",
              "      <td>11</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.047485</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>0.109517</td>\n",
              "      <td>0.164216</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32763</th>\n",
              "      <td>0.121928</td>\n",
              "      <td>32770</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.040072</td>\n",
              "      <td>0.085509</td>\n",
              "      <td>32764</td>\n",
              "      <td>32765</td>\n",
              "      <td>32766</td>\n",
              "      <td>32767</td>\n",
              "      <td>32768</td>\n",
              "      <td>32769</td>\n",
              "      <td>0.121928</td>\n",
              "      <td>0.147955</td>\n",
              "      <td>32769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32764</th>\n",
              "      <td>0.147955</td>\n",
              "      <td>32771</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.040072</td>\n",
              "      <td>0.085509</td>\n",
              "      <td>0.121928</td>\n",
              "      <td>32765</td>\n",
              "      <td>32766</td>\n",
              "      <td>32767</td>\n",
              "      <td>32768</td>\n",
              "      <td>32769</td>\n",
              "      <td>32770</td>\n",
              "      <td>0.147955</td>\n",
              "      <td>0.163166</td>\n",
              "      <td>32770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32765</th>\n",
              "      <td>0.163166</td>\n",
              "      <td>32772</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.040072</td>\n",
              "      <td>0.085509</td>\n",
              "      <td>0.121928</td>\n",
              "      <td>0.147955</td>\n",
              "      <td>32766</td>\n",
              "      <td>32767</td>\n",
              "      <td>32768</td>\n",
              "      <td>32769</td>\n",
              "      <td>32770</td>\n",
              "      <td>32771</td>\n",
              "      <td>0.163166</td>\n",
              "      <td>0.129599</td>\n",
              "      <td>32771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32766</th>\n",
              "      <td>0.129599</td>\n",
              "      <td>32773</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.040072</td>\n",
              "      <td>0.085509</td>\n",
              "      <td>0.121928</td>\n",
              "      <td>0.147955</td>\n",
              "      <td>0.163166</td>\n",
              "      <td>32767</td>\n",
              "      <td>32768</td>\n",
              "      <td>32769</td>\n",
              "      <td>32770</td>\n",
              "      <td>32771</td>\n",
              "      <td>32772</td>\n",
              "      <td>0.129599</td>\n",
              "      <td>0.122734</td>\n",
              "      <td>32772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32767</th>\n",
              "      <td>0.122734</td>\n",
              "      <td>32774</td>\n",
              "      <td>0.040072</td>\n",
              "      <td>0.085509</td>\n",
              "      <td>0.121928</td>\n",
              "      <td>0.147955</td>\n",
              "      <td>0.163166</td>\n",
              "      <td>0.129599</td>\n",
              "      <td>32768</td>\n",
              "      <td>32769</td>\n",
              "      <td>32770</td>\n",
              "      <td>32771</td>\n",
              "      <td>32772</td>\n",
              "      <td>32773</td>\n",
              "      <td>0.122734</td>\n",
              "      <td>0.097022</td>\n",
              "      <td>32773</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32768 rows  17 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      generation Time_step  ... fore_generation end_of_Time_step\n",
              "                            ...               1                 \n",
              "0       0.000000         7  ...        0.000000                6\n",
              "1       0.000000         8  ...        0.000000                7\n",
              "2       0.000000         9  ...        0.047485                8\n",
              "3       0.047485        10  ...        0.109517                9\n",
              "4       0.109517        11  ...        0.164216               10\n",
              "...          ...       ...  ...             ...              ...\n",
              "32763   0.121928     32770  ...        0.147955            32769\n",
              "32764   0.147955     32771  ...        0.163166            32770\n",
              "32765   0.163166     32772  ...        0.129599            32771\n",
              "32766   0.129599     32773  ...        0.122734            32772\n",
              "32767   0.122734     32774  ...        0.097022            32773\n",
              "\n",
              "[32768 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n49WMi0rBKee",
        "colab_type": "code",
        "outputId": "4322da9c-107a-4406-a38a-5d4879c23dcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "source": [
        "from kerashistoryplot.callbacks import PlotHistory\n",
        "#plot_callback = PlotHistory(figsize=(15, 3), n_cols=3, batches=False)\n",
        "\n",
        "multimodel.fit_generator(\n",
        "    rolling_chunked, model=\"forecast\", verbose=1, epochs=10,\n",
        "    reset_weights=True,\n",
        "    workers=4\n",
        "    #, callbacks=[plot_callback]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/10\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0366 - mean_absolute_error: 0.1092\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 2s 101ms/step - loss: 0.0242 - mean_absolute_error: 0.1002\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 2s 97ms/step - loss: 0.0187 - mean_absolute_error: 0.0921\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 2s 102ms/step - loss: 0.0152 - mean_absolute_error: 0.0834\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 2s 99ms/step - loss: 0.0130 - mean_absolute_error: 0.0779\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 0.0116 - mean_absolute_error: 0.0739\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0103 - mean_absolute_error: 0.0699\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 2s 100ms/step - loss: 0.0094 - mean_absolute_error: 0.0665\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 2s 106ms/step - loss: 0.0087 - mean_absolute_error: 0.0642\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 2s 101ms/step - loss: 0.0082 - mean_absolute_error: 0.0613\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<timeserio.keras.callbacks.HistoryLogger at 0x7fb35aa639b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfOTeLQ6BKej",
        "colab_type": "text"
      },
      "source": [
        "persist the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad8xS6LXmF0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_file=\"/tmp/model.pickle\"\n",
        "network_file=\"/tmp/network.pickle\"\n",
        "weights_file=\"/tmp/weights.pickle\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmOgE2qFBKek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from timeserio.utils.pickle import loadf, dumpf\n",
        "dumpf(multimodel, model_file)\n",
        "dumpf(multinetwork, network_file)\n",
        "dumpf(multinetwork.weights, weights_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTpxWNznlsHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(model_file)\n",
        "files.download(network_file)\n",
        "files.download(weights_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEpoZ9dUTTRp",
        "colab_type": "code",
        "outputId": "50fa5a45-9589-460d-edfe-587734929f94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "multimodel.multinetwork.weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'encoder': [array([[[0.24813499]]], dtype=float32),\n",
              "  array([0.00163302], dtype=float32),\n",
              "  array([1.0501057], dtype=float32),\n",
              "  array([0.11739083], dtype=float32),\n",
              "  array([0.03460965], dtype=float32),\n",
              "  array([0.00223897], dtype=float32)],\n",
              " 'forecast': [array([[[0.24813499]]], dtype=float32),\n",
              "  array([0.00163302], dtype=float32),\n",
              "  array([1.0501057], dtype=float32),\n",
              "  array([0.11739083], dtype=float32),\n",
              "  array([0.03460965], dtype=float32),\n",
              "  array([0.00223897], dtype=float32),\n",
              "  array([[ 0.2842112 , -0.5701866 ,  0.12303936, -0.31303486,  0.34182647,\n",
              "           0.22236133,  0.4843851 , -0.03378399],\n",
              "         [-0.24248841,  0.54876417,  0.59752405, -0.23054275, -0.0557189 ,\n",
              "           0.27279264,  0.42946422, -0.5015413 ],\n",
              "         [ 0.38957378, -0.09641979,  0.24506073, -0.28375766, -0.49676055,\n",
              "           0.41025755, -0.2153305 ,  0.41597456],\n",
              "         [ 0.627032  , -0.4362499 , -0.56706876, -0.45808616, -0.12986566,\n",
              "           0.09596018, -0.01438249,  0.5095536 ],\n",
              "         [ 0.19646725, -0.45259818,  0.5811543 , -0.37319058, -0.1258243 ,\n",
              "           0.2665749 ,  0.11988477,  0.19078411],\n",
              "         [-0.53358936, -0.04561362,  0.58978295,  0.7126915 , -0.13509671,\n",
              "           0.09948167, -0.20511676,  0.32246616],\n",
              "         [ 0.6476337 , -0.11289365,  0.37200958, -0.05426198,  0.14210585,\n",
              "           0.2745294 , -0.4288272 , -0.15140787]], dtype=float32),\n",
              "  array([ 0.02691156, -0.02003043,  0.02990297,  0.09055232, -0.01360983,\n",
              "          0.0035215 , -0.01429082,  0.03771398], dtype=float32),\n",
              "  array([[-0.2715934 , -0.07541662,  0.26889166, -0.41315255, -0.17522581,\n",
              "          -0.5039476 ,  0.49787363, -0.12865351],\n",
              "         [-0.08667169, -0.334741  ,  0.34280202, -0.28206813, -0.17593141,\n",
              "          -0.42933148,  0.43470994, -0.24743974],\n",
              "         [-0.19142342,  0.5395536 , -0.06558125, -0.14819063, -0.08092739,\n",
              "          -0.27866256,  0.54791445,  0.04785928],\n",
              "         [ 0.18578327,  0.26024657, -0.3463274 , -0.16097647, -0.62980074,\n",
              "          -0.298759  ,  0.51921636, -0.6971616 ],\n",
              "         [ 0.42968756, -0.08712895,  0.11233088, -0.24971771,  0.21823113,\n",
              "          -0.4193551 , -0.584756  ,  0.16020516],\n",
              "         [ 0.32800964,  0.33294964,  0.45624328,  0.6037684 ,  0.24448475,\n",
              "          -0.34581894, -0.4282642 ,  0.4822129 ],\n",
              "         [-0.34587878,  0.1413651 ,  0.32886964,  0.08179951, -0.18184075,\n",
              "          -0.1886845 , -0.23058169,  0.19907679],\n",
              "         [-0.14093725, -0.3325799 , -0.4767196 ,  0.13697237,  0.2259784 ,\n",
              "          -0.33859217,  0.21953505, -0.339103  ]], dtype=float32),\n",
              "  array([-0.0172146 ,  0.0294539 ,  0.01166283,  0.10955931, -0.03384056,\n",
              "          0.        ,  0.0316782 ,  0.03803404], dtype=float32),\n",
              "  array([[ 0.2916956 , -0.32092574],\n",
              "         [-0.08069722,  0.08476583],\n",
              "         [-0.545896  , -0.17700067],\n",
              "         [ 0.11575575,  0.4768864 ],\n",
              "         [-0.34425196, -0.21776348],\n",
              "         [-0.3550478 , -0.7041948 ],\n",
              "         [ 0.4266486 ,  0.15326738],\n",
              "         [ 0.393907  , -0.47421688]], dtype=float32),\n",
              "  array([0.01062865, 0.07582617], dtype=float32)]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEvo9LMxBKep",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate performance on test data\n",
        "We can evaluate the model on the validation data generator, which can also be out-of-memory:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2WZjvmwBKes",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rolling_chunked_test=RollingForecastBatchGeneratorChunked(\n",
        "    df=df_test,id_column=\"country\",lookback_steps=6,forecast_steps=2,lookback_columns=[\"generation\", \"Time_step\"],\n",
        "    forecast_columns=[\"generation\", \"Time_step\"],\n",
        "     last_step_columns=[\"Time_step\"],batch_size=2**15,\n",
        "     )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOBayckeBKev",
        "colab_type": "code",
        "outputId": "81317c8f-558f-4949-90a5-cc2d9f6083af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "multimodel.evaluate_generator(rolling_chunked_test, model=\"forecast\", verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 60ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.006176444236189127, 0.053669482469558716]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp7Z1fsMBKey",
        "colab_type": "text"
      },
      "source": [
        "While the model takes longer to train (and longer still with practical encoder architectures), it can be tuned to achieve higher performanec, especially if encodings are combined with datetime features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdJBSf6QHNGx",
        "colab_type": "code",
        "outputId": "45afe2b1-d144-4a3e-e761-33de91a2cfbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "from kerashistoryplot.plot import plot_history\n",
        "history = multimodel.history[-1][\"history\"]\n",
        "plot_history(history, figsize=(15, 3), n_cols=3);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAADQCAYAAADxn5GHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x216 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}